{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis\n",
    "- Currently this does not work very well \n",
    "- Seems like the correct analysis is applied ~50% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment scores and labels updated successfully.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from credentials import ipCred, usernameCred, passwordCred, databaseCred\n",
    "\n",
    "# Use your fine-tuned model (change paths as needed)\n",
    "classifier = pipeline(\n",
    "    task=\"text-classification\", \n",
    "    model=\"./finbert-finetuned\", \n",
    "    tokenizer=\"./finbert-finetuned\", \n",
    "    device=-1\n",
    ")\n",
    "\n",
    "ticker = 'AAPL'\n",
    "db_config = {\n",
    "    'host': ipCred,\n",
    "    'user': usernameCred,\n",
    "    'password': passwordCred,\n",
    "    'database': databaseCred\n",
    "}\n",
    "\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "\n",
    "# --- Cursor A: Fetch rows that need sentiment scores ---\n",
    "cursor_fetch = conn.cursor()\n",
    "fetch_query = f\"\"\"\n",
    "    SELECT news_id, summary\n",
    "    FROM {ticker}_news\n",
    "    WHERE sentiment IS NULL\n",
    "    LIMIT 10000;\n",
    "\"\"\"\n",
    "cursor_fetch.execute(fetch_query)\n",
    "rows = cursor_fetch.fetchall()\n",
    "cursor_fetch.close()  # Close fetch cursor\n",
    "\n",
    "if not rows:\n",
    "    print(\"No rows to update.\")\n",
    "    conn.close()\n",
    "    exit()\n",
    "\n",
    "# Filter out rows with empty summaries and unzip IDs and summaries\n",
    "id_summary_pairs = [(news_id, summary) for news_id, summary in rows if summary]\n",
    "if not id_summary_pairs:\n",
    "    print(\"No valid summaries found.\")\n",
    "    conn.close()\n",
    "    exit()\n",
    "\n",
    "news_ids, summaries = zip(*id_summary_pairs)\n",
    "\n",
    "# Process summaries in batches\n",
    "batch_size = 32\n",
    "results = []\n",
    "for i in range(0, len(summaries), batch_size):\n",
    "    batch = list(summaries[i:i+batch_size])\n",
    "    batch_results = classifier(batch, truncation=True)\n",
    "    results.extend(batch_results)\n",
    "\n",
    "# --- Cursor B: Update rows with both numeric and label sentiment ---\n",
    "cursor_update = conn.cursor()\n",
    "update_query = f\"\"\"\n",
    "    UPDATE {ticker}_news\n",
    "    SET sentiment = %s, sentiment_label = %s\n",
    "    WHERE news_id = %s\n",
    "\"\"\"\n",
    "\n",
    "# Process each result: store numeric score and its corresponding label.\n",
    "for news_id, result in zip(news_ids, results):\n",
    "    r = result[0] if isinstance(result, list) else result\n",
    "    label = r['label'].upper()  # e.g., \"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"\n",
    "    score = r['score']\n",
    "    \n",
    "    # Compute bipolar sentiment for the numeric column:\n",
    "    if label == \"POSITIVE\":\n",
    "        sentiment_score = score\n",
    "    elif label == \"NEGATIVE\":\n",
    "        sentiment_score = -score\n",
    "    else:\n",
    "        sentiment_score = 0.0\n",
    "\n",
    "    # Update both columns: numeric sentiment and the label string.\n",
    "    cursor_update.execute(update_query, (sentiment_score, label, news_id))\n",
    "\n",
    "conn.commit()\n",
    "cursor_update.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Sentiment scores and labels updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Chat - PAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "def get_sentiment(text):\n",
    "    prompt = f\"Classify the sentiment of the following news summary as either POSITIVE, NEUTRAL, or NEGATIVE:\\n\\n{text}\\n\\nAnswer:\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",  # or \"gpt-3.5-turbo\" if using ChatCompletion API\n",
    "        prompt=prompt,\n",
    "        max_tokens=1,\n",
    "        temperature=0.0,  # low temperature for deterministic output\n",
    "    )\n",
    "    label = response.choices[0].text.strip().upper()\n",
    "    return label\n",
    "\n",
    "# Example usage:\n",
    "summary = \"The company reported record earnings this quarter and shares soared.\"\n",
    "print(get_sentiment(summary))  # Expected output: POSITIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINE TUNING FINBERT\n",
    "# Using https://arc.net/l/quote/zbvxjftu this data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### note: please do not run this if you do not have a beefy computer with a GPU you will cook your machine (actually) (genuinely)(this is warning)\n",
    "##### Currently takes .5 hours on m4 mac mini pro w 24GB vRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909e825f3bb04b849dd39e22950b4854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4673 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30e433e17744256b72d0a1001307df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1169 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6568988c6d0452b9b6743ffc229d2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4673 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a8dcfb5fe245039346d6bfb7845dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1169 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d8f2e6c628444e9a78f0ebfcf05c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4673 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ffd9500a77448da7737c13ce07963f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1169 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 54\u001b[0m\n\u001b[1;32m     45\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     46\u001b[0m     model_checkpoint,\n\u001b[1;32m     47\u001b[0m     num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     problem_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# 7. Set up training args & Trainer\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./finbert-finetuned\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#learning rate higher means speeding up the training, but may overconverge (overshoot) where you want to be\u001b[39;49;00m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# does not let the model overfit the data\u001b[39;49;00m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./logs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     67\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     68\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     72\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# 8. Train, save, evaluate\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# Convert CSV into Pandas Data frame\n",
    "df = pd.read_csv(\"labeledNews.csv\")  # columns: \"Sentence\", \"Sentiment\"\n",
    "\n",
    "# convert pandas dataframe to hugging face dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "#splitting the data randomly into training and testing (currently 80% train and 20% test)\n",
    "train_test = dataset.train_test_split(test_size=0.2)\n",
    "dataset_train = train_test[\"train\"]\n",
    "dataset_val = train_test[\"test\"]\n",
    "\n",
    "# cleaning and mapping the data\n",
    "def cleanData(example):\n",
    "    example[\"text\"] = example[\"Sentence\"]\n",
    "    return example\n",
    "\n",
    "# mapping the cleanData function to the dataset\n",
    "dataset_train = dataset_train.map(cleanData)\n",
    "dataset_val = dataset_val.map(cleanData)\n",
    "\n",
    "labelToID = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "\n",
    "def encode_labels(example):\n",
    "    example[\"label\"] = labelToID[example[\"Sentiment\"].lower()]\n",
    "    return example\n",
    "\n",
    "dataset_train = dataset_train.map(encode_labels)\n",
    "dataset_val = dataset_val.map(encode_labels)\n",
    "\n",
    "# tokenize the data\n",
    "model_checkpoint = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "dataset_train = dataset_train.map(tokenize_function, batched=True)\n",
    "dataset_val = dataset_val.map(tokenize_function, batched=True)\n",
    "\n",
    "# loading up the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=3,\n",
    "    id2label={0: \"negative\", 1: \"neutral\", 2: \"positive\"},\n",
    "    label2id={\"negative\": 0, \"neutral\": 1, \"positive\": 2},\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "# 7. Set up training args & Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finbert-finetuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5, #learning rate higher means speeding up the training, but may overconverge (overshoot) where you want to be\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01, # does not let the model overfit the data\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_val,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# 8. Train, save, evaluate\n",
    "trainer.train()\n",
    "model.save_pretrained(\"./finbert-finetuned\")\n",
    "tokenizer.save_pretrained(\"./finbert-finetuned\")\n",
    "\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
